{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Interrupted Time Series Analysis with Prophet on Nigeria data\n",
    "\n",
    "This tutorial pertains to training and evaluating an interrupted time series model in python using the open-ource Prophet libarary by Facebook Inc. (https://facebook.github.io/prophet/)\n",
    "\n",
    "We will walk through 6 main steps:\n",
    "\n",
    "1) Installing and/loading loading required libraries<br>\n",
    "2) Loading Nigeria dataset<br>\n",
    "3) Data Preparation\n",
    "3) Getting forecasts<br>\n",
    "4) Tuning hyperparameters<br> \n",
    "5) Get forecasts using tuned hyperparameters<br>\n",
    "6) Evaluation model performance using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and/or Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall be using a Python 3.8 environment since Prophet is compatible with < 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install hampel\n",
    "# !pip install scipy\n",
    "# !pip install openpyxl # extension to read excel files\n",
    "# !pip install pystan==2.19.1.1\n",
    "# !pip install prophet --no-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "from scipy.stats import wilcoxon, t, sem\n",
    "from hampel import hampel\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and cleaning the Nigeria dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step involves loading the Excel sheet with the Nigeria essential health services data; Antenatal Visits, maternal deaths and facility deliveries.<br>\n",
    "\n",
    "In this work, we use Antenatal Visits and facility deliveries from January 2017 through December 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load Antenatal Visits data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anc_data_columns = ['organisationunitname', 'ANC Syphilis case treated','ANC Syphilis test done ', 'ANC Syphilis test positive ',\n",
    "                      'Antenatal 1st (booking) visit 20 weeks or later','periodname',\n",
    "                      'Antenatal 1st (booking) visit before 20 weeks', 'Antenatal 4th Visit','Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ng_dhs_anc_data = pd.read_csv('anc_visits_nigeria.csv')\n",
    "ng_dhs_anc_data['Date'] = pd.to_datetime(ng_dhs_anc_data['periodname'])\n",
    "ng_dhs_anc_data.sort_values(by = 'Date')\n",
    "ng_dhs_anc_data['Year'] = ng_dhs_anc_data.Date.dt.year\n",
    "ng_dhs_anc_data['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ng_dhs_anc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ng_dhs_anc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Load facility deliveries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_deliveries_columns = ['Date','organisationunitname','Deliveries with complications - mother only',\n",
    "                               'Preterm birth (<37th Weeks)','Deliveries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ng_dhs_facility_deliveries = pd.read_csv('facility_deliveries_nigeria.csv')\n",
    "ng_dhs_facility_deliveries['Date'] = pd.to_datetime(ng_dhs_facility_deliveries['periodname'])\n",
    "ng_dhs_facility_deliveries = ng_dhs_facility_deliveries[facility_deliveries_columns]\n",
    "ng_dhs_facility_deliveries['Year'] = ng_dhs_facility_deliveries.Date.dt.year\n",
    "ng_dhs_facility_deliveries['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ng_dhs_facility_deliveries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the deliveries column has a lot of missing data, thus cannot be usefull in this work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Merge all dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will merge the two dataframes; Antenatal Visits and Facility Deliveries (Deliveries with complications - mother only, Preterm births) to work with one dataframe onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['Antenatal 4th Visit','Preterm birth (<37th Weeks)','Deliveries with complications - mother only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "facility_anc_merge = ng_dhs_facility_deliveries.merge(ng_dhs_anc_data, how='left', on=['Date','Year','organisationunitname'])\n",
    "facility_anc_merge = facility_anc_merge [['Date','Year','organisationunitname'] + final_columns ]\n",
    "facility_anc_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Aggreagate the State level data into Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_regions (row):\n",
    "    if row['organisationunitname'] in South_South:\n",
    "        return 'South South'\n",
    "    if row['organisationunitname'] in South_West:\n",
    "        return 'South West'\n",
    "    if row['organisationunitname'] in South_East:\n",
    "        return 'South East'\n",
    "    if row['organisationunitname'] in North_Central:\n",
    "        return 'North Central'\n",
    "    if row['organisationunitname'] in North_East:\n",
    "        return 'North East'\n",
    "    if row['organisationunitname'] in North_West:\n",
    "        return 'North West'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "South_South = [\"ak Akwa-Ibom State\",\"by Bayelsa State\",\"cr Cross River State\",\"de Delta State\",\"ed Edo State\",\"ri Rivers State\"] \n",
    "South_East = [\"ab Abia State\",\" an Anambra state\",\"eb Ebonyi State\",\"en Enugu State\",\"im Imo State\"]\n",
    "South_West = [\"ek Ekiti State\",\"la Lagos State\",\"og Ogun State\",\"on Ondo State\",\"os Osun State\",\"oy Oyo State\"]\n",
    "North_East = [\"ad Adamawa State\",\"ba Bauchi State\",\"bo Borno State\",\"go Gombe State\",\"ta Taraba State\",\"yo Yobe State\"]\n",
    "North_West = [\"ji Jigawa State\",\"kd Kaduna State\",\"kn Kano State\",\"kt Katsina State\",\"ke Kebbi State\",\"so Sokoto State\",\"za Zamfara State\"]\n",
    "North_Central = [\"be Benue State\",\"ko Kogi State\",\"kw Kwara State\",\"na Nasarawa State\",\"ni Niger State\",\"pl Plateau State\",\"fc Federal Capital Territory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_copy = facility_anc_merge.copy() # Make a copy of the dataframe\n",
    "\n",
    "# Map Regions to States\n",
    "df_copy['Region'] = df_copy.apply(aggregate_to_regions, axis = 1)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check if we have any outliers and deal with them before running the analysis. We shall do this by visualising the data. <br>\n",
    "There are other techniques to identify outliers like boxplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def plot_sphaghetti(dat, id_var, x_var, y_var, title):\n",
    "    \"\"\"\n",
    "    Plot sphaghetti \n",
    "    \n",
    "    @param dat: data in long format (dataframe)\n",
    "    @param id_var: column name of unique ids of individuals (str)\n",
    "    @param x_var: name of x variable (str)\n",
    "    @param y_var: name of y variable (str)\n",
    "    @param sample_size: sample size (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(12,7)})\n",
    "    mpl.rcParams['font.size'] = 8.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "    ids = dat[id_var]\n",
    " \n",
    "  \n",
    "    for i in ids:\n",
    "        df = dat[[x_var, y_var]][dat[id_var] == i]\n",
    "        df[y_var] = df[y_var].fillna(df[y_var].mean())\n",
    "        #z = np.abs(stats.zscore(df[y_var]))\n",
    "        #df = df[z<3]\n",
    "        plt.plot(df[x_var],df[y_var], marker='', color='black', linewidth=0.1, alpha=0.1)\n",
    "    \n",
    "    plt.ylabel('Count', fontsize = 18, fontweight='bold')\n",
    "    #plt.xlabel(x_var, fontsize = 14, fontweight='bold')\n",
    "    \n",
    "    plt.title(title,fontsize = 20, fontweight='bold')\n",
    "    plt.xticks(rotation=90, fontsize =18, fontweight='bold')\n",
    "    plt.yticks(fontsize =18, fontweight='bold')\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    plt.savefig(\"plots/{}.png\".format(title),  dpi=300, bbox_inches='tight')\n",
    "    plt.xlabel('Date')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in final_columns:\n",
    "    title = '{} per Organizational Unit'.format(column)\n",
    "    plot_sphaghetti(df_copy,'organisationunitname', 'Date', column , title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_mappings = {'Antenatal 4th Visit':'4th Antenatal Visit',\n",
    "                'Preterm birth (<37th Weeks)':'Preterm deliveries ',\n",
    "                'Deliveries with complications - mother only':'Complicated Deliveries(Mother)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers\n",
    "def remove_outliers(x):\n",
    "    if len(set(x)) == 1 or x.isnull().all():\n",
    "        return x\n",
    "    x = x.fillna(x.mean())\n",
    "    x = pd.Series([int(i) for i in x])\n",
    "    return hampel(x, window_size=5, n=3, imputation=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for typ in ['Antenatal 4th Visit']:\n",
    "    df_copy[typ] = df_copy.groupby('organisationunitname')[typ].transform(remove_outliers)\n",
    "    df_copy[typ] = df_copy[typ].astype(int)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in ['Antenatal 4th Visit']:\n",
    "    title = '{} per Organizational Unit'.format(column)\n",
    "    plot_sphaghetti(df_copy,'organisationunitname', 'Date', column , title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above it is visible, that the outlier has been delt with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Prepare the data for the ITS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the Missing values\n",
    "def fill_values(dataset,col):\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].rolling(8,min_periods=1).mean())\n",
    "    return dataset[col]\n",
    "\n",
    "for col in final_columns:\n",
    "    fill_values(df_copy, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert datatype to int\n",
    "for typ in final_columns:\n",
    "    df_copy[typ] = df_copy[typ].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate monthly total for each region\n",
    "df_copy = df_copy.groupby(['Region','Date'])[final_columns].sum().reset_index()\n",
    "df_copy = df_copy.copy()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Set labels for easy plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_label_original = {'Antenatal 4th Visit':'Antenatal 4th Visit',\n",
    "                 'Preterm birth (<37th Weeks)':'Preterm births',\n",
    "                 'Deliveries with complications - mother only': 'Deliveries with complications:Mother'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive labels for y axis\n",
    "y_axis_label  = {'Antenatal 4th Visit':'4th antenatal visits (n)', \n",
    "                'Preterm birth (<37th Weeks)':'number of preterm deliveries',\n",
    "                'Deliveries with complications - mother only':'number of complicated deliveries'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions = df_copy['Region'].unique().tolist()\n",
    "regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Getting forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train an ITS models the ANC Visits, Preterm births and Complicated Deliveries(Mother only) data. We train the model using data up to Feb 01, 2020, and then use the model to predict the outcome for the remaining months in our data (March 2020 - December 2020). We then compare the trends in the actual and predicted outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Specify prediction period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_start_date='2020-03-01'\n",
    "prediction_end_date='2020-12-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Get forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_forecasts(location, outcome, data, seasonality_mode='additive', changepoint_prior_scale=0.05, seasonality_prior_scale=10.0, prediction_start_date='2020-03-01', prediction_end_date='2020-06-01'):\n",
    "    \n",
    "    '''\n",
    "    Function to get the prophet forecasts. \n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    data: Dataframe with date and the outcome value for the geographical unit and outcome. (pd.DataFrame)\n",
    "    seasonality_mode: tuned prophet model parameter (string)\n",
    "    changepoint_prior_scale: tuned prophet model parameter (double)\n",
    "    seasonality_prior_scale: tuned prophet model parameter (double)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    prediction_end_date: Prediction end date (datetime)\n",
    "    \n",
    "    '''\n",
    "    df = data.copy()  \n",
    "\n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "    \n",
    "    prediction_end_date = datetime.strptime(prediction_end_date, '%Y-%m-%d')\n",
    "    \n",
    "    df = df[df['ds']<=prediction_end_date] \n",
    "\n",
    "    df_training = df[df['ds']<prediction_start_date] \n",
    "\n",
    "    df_test = df[df['ds']>=prediction_start_date]\n",
    "    \n",
    "    m = Prophet(interval_width=.95, \n",
    "            growth ='linear',\n",
    "            yearly_seasonality=False, \n",
    "            weekly_seasonality = False, \n",
    "            daily_seasonality = False,\n",
    "            seasonality_mode = seasonality_mode,\n",
    "            changepoint_prior_scale = changepoint_prior_scale,\n",
    "            seasonality_prior_scale = seasonality_prior_scale,\n",
    "            ).add_seasonality(\n",
    "                name='yearly',\n",
    "                period = 365,\n",
    "                fourier_order = 5\n",
    "            )\n",
    "\n",
    "    m.fit(df_training)\n",
    "\n",
    "    future = pd.DataFrame(df['ds'], columns = ['ds'])\n",
    "    \n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    forecast['y'] = [i for i in df['y']]\n",
    "    \n",
    "    forecast['change'] = forecast['y'] - forecast['yhat']\n",
    "    \n",
    "    forecast['percent_change'] = forecast.apply(lambda row: round((row.y - row.yhat)/row.yhat *100,2), axis =1)\n",
    "            \n",
    "    \n",
    "    return forecast[['ds','y','yhat','change','percent_change','yhat_lower','yhat_upper','trend','trend_lower','trend_upper']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get forecast for each region and outcome\n",
    "forecast_dict = {}\n",
    "for region in regions:\n",
    "    measures_forecast = {}\n",
    "    for measure in final_columns:\n",
    "        data = df_copy.loc[df_copy['Region'] == region].copy()[[measure,'Date','Region']]\n",
    "        data = data[['Date', measure]]\n",
    "        data.columns = ['ds','y']\n",
    "        \n",
    "        forecast = get_forecasts(location = region,\n",
    "                                  outcome = measure,\n",
    "                                  data = data, \n",
    "                                  prediction_start_date = prediction_start_date,\n",
    "                                  prediction_end_date = prediction_end_date)\n",
    "        \n",
    "        measures_forecast[measure] = forecast\n",
    "        \n",
    "    forecast_dict[region] = measures_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_dict['North Central']['Antenatal 4th Visit'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_its(location, outcome, forecast, prediction_start_date, prediction_end_date, normalise = False):\n",
    "    '''\n",
    "    Function to plot the forecast counts.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    forecast: Dataframe with the prophet forecast output for the geographical unit and outcome(pd.DataFrame)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    prediction_end_date: Prediction end date (datetime)\n",
    "    normalise: Data normalised (boolean)\n",
    "    \n",
    "    '''\n",
    "    sns.set(rc={'figure.figsize':(10,8)})\n",
    "    sns.set_style(\"white\")\n",
    "    mpl.rcParams['font.size'] = 8.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "    prediction_end_date = datetime.strptime(prediction_end_date, '%Y-%m-%d')\n",
    "    \n",
    "    plt.axvspan(xmin = prediction_start_date , xmax=prediction_end_date, color='grey', alpha=0.2, lw=0)\n",
    "    \n",
    "    plt.scatter(forecast['ds'],forecast['y'], facecolors='none', edgecolors='black', s =20, label = 'observed values')\n",
    "    plt.xlim([forecast['ds'].min(),prediction_end_date])\n",
    "    \n",
    "    plt.plot(forecast['ds'],forecast['yhat'], color = '#33adff', label ='predicted values')\n",
    "    plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='#33adff', alpha=0.25)\n",
    "\n",
    "    plt.plot(forecast['ds'],forecast['trend'], color = 'red', linestyle =\"--\", label ='predicted trend')\n",
    "    plt.fill_between(forecast['ds'], forecast['trend_lower'], forecast['trend_upper'], color='red', alpha=0.2)\n",
    "    \n",
    "    plt.xticks(rotation=90, fontsize =18, fontweight='bold')\n",
    "    plt.yticks(fontsize =18, fontweight='bold') \n",
    "    \n",
    "    plt.xlabel('') \n",
    "   \n",
    "    \n",
    "    if normalise:\n",
    "        plt.ylabel('count per 100k', fontsize =18, fontweight='bold')\n",
    "        title = '{} in {} normalised'.format(outcome_label[outcome],location)\n",
    "    else:\n",
    "        plt.ylabel('counts', fontsize =18, fontweight='bold')\n",
    "        title = '{} in {} '.format(outcome_label_original[outcome],location)\n",
    "        \n",
    "    plt.title(title,fontsize = 20, fontweight='bold')\n",
    "    plt.legend(loc='upper left',fontsize=12)\n",
    "    plt.savefig(\"plots/\"+title+\"_its.png\", dpi=300,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot forecast for each region and outcome\n",
    "for region in forecast_dict.keys():\n",
    "    for measure in forecast_dict[region].keys():\n",
    "        plot_its(location = region,        \n",
    "                     outcome = measure,\n",
    "                     forecast = forecast_dict[region][measure],\n",
    "                     prediction_start_date = prediction_start_date,\n",
    "                     prediction_end_date = prediction_end_date, \n",
    "                     normalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_cumulative(location, outcome, forecast, prediction_start_date, prediction_end_date, normalise = False):\n",
    "    '''\n",
    "    Function to plot the cumulative forecast.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    forecast: Dataframe with the prophet forecast output for the geographical unit and outcome (pd.DataFrame)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    prediction_end_date: Prediction end date (datetime)\n",
    "    normalise: Data normalised (boolean)\n",
    "    \n",
    "    '''\n",
    "    sns.set(rc={'figure.figsize':(10,8)})\n",
    "    sns.set_style(\"white\")\n",
    "    mpl.rcParams['font.size'] = 8.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    \n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "    prediction_end_date = datetime.strptime(prediction_end_date, '%Y-%m-%d')\n",
    "    plt.xlim([forecast['ds'].min(),prediction_end_date])\n",
    "    plt.axvspan(xmin = prediction_start_date , xmax=prediction_end_date, color='grey', alpha=0.2, lw=0)\n",
    "    plt.plot(forecast['ds'],forecast['y'].cumsum(), color = 'orange', label ='actual values')    \n",
    "    plt.plot(forecast['ds'],forecast['yhat'].cumsum(), color = '#33adff', label ='predicted values')\n",
    "    \n",
    "    plt.xticks(rotation=90, fontsize =18, fontweight='bold')\n",
    "    plt.yticks(fontsize =18, fontweight='bold') \n",
    "    \n",
    "    plt.xlabel('') \n",
    " \n",
    "    if normalise:\n",
    "        plt.ylabel('Cumulative counts per 100k', fontsize =18, fontweight='bold')\n",
    "        title = '{} in {} Region normalised'.format(outcome_label[outcome],location)\n",
    "    else:\n",
    "        plt.ylabel('Cumulative counts', fontsize =18, fontweight='bold')\n",
    "        title = '{} in {} Region'.format(outcome_label_original[outcome],location)\n",
    "\n",
    "    plt.title(title,fontsize = 20, fontweight='bold')\n",
    "    plt.legend(loc='upper left',fontsize=12)\n",
    "    plt.savefig(\"plots/\"+title+\"_its.png\", dpi=300,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Cumulative forecast for each region and outcome\n",
    "for region in forecast_dict.keys():\n",
    "    for measure in forecast_dict[region].keys():\n",
    "        plot_cumulative(location = region,        \n",
    "                     outcome = measure,\n",
    "                     forecast = forecast_dict[region][measure],\n",
    "                     prediction_start_date = prediction_start_date,\n",
    "                     prediction_end_date = prediction_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(location, outcome, forecast, prediction_start_date, prediction_end_date):\n",
    "    \n",
    "    '''\n",
    "    Function to get the metrics from the forecast.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    forecast: Dataframe with the prophet forecast output for the geographical unit and outcome (pd.DataFrame)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    prediction_end_date: Prediction end date (datetime)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "    prediction_end_date = datetime.strptime(prediction_end_date, '%Y-%m-%d')\n",
    "\n",
    "    df_before = forecast[forecast['ds']<prediction_start_date]\n",
    "\n",
    "    df_after = forecast[(forecast['ds']>=prediction_start_date) & (forecast['ds']<=prediction_end_date)]\n",
    "\n",
    "    metrics = dict()\n",
    "    metrics['location'] = location\n",
    "    metrics['outcome'] = outcome\n",
    "    \n",
    "    metrics['mape_before'] = round(np.mean(((df_before['y'] - df_before['yhat'])/df_before['y']).abs()),2)\n",
    "    metrics['mape_after'] = round(np.mean(((df_after['y'] - df_after['yhat'])/df_after['y']).abs()),2)\n",
    "    \n",
    "    metrics['actual_mean_before'] = int(round(df_before['y'].mean(),0))\n",
    "    metrics['predicted_mean_before'] = int(round(df_before['yhat'].mean(),0))\n",
    "    metrics['actual_mean_after'] = int(round(df_after['y'].mean(),0))\n",
    "    metrics['predicted_mean_after'] = int(round(df_after['yhat'].mean(),0))\n",
    "    \n",
    "    metrics['actual_median_before'] = int(round(df_before['y'].median(),0))\n",
    "    metrics['predicted_median_before'] = int(round(df_before['yhat'].median(),0))\n",
    "    metrics['actual_median_after'] = int(round(df_after['y'].median(),0))\n",
    "    metrics['predicted_median_after'] = int(round(df_after['yhat'].median(),0))\n",
    "    \n",
    "    metrics['mean_change_before'] = np.mean(df_before['change'])\n",
    "    metrics['wilcoxon_change_before'] = (wilcoxon(df_before['change'] ))\n",
    "    metrics['mean_change_after'] = np.mean(df_after['change'])\n",
    "    metrics['wilcoxon_change_after'] = (wilcoxon(df_after['change'] ))\n",
    "        \n",
    "    metrics['change_conf_int_before'] = t.interval(alpha=0.95, df=len(df_before['change'])-1, loc=np.mean(df_before['change']), scale=sem(df_before['change']))\n",
    "    metrics['change_conf_int_after'] = t.interval(alpha=0.95, df=len(df_after['change'])-1, loc=np.mean(df_after['change']), scale=sem(df_after['change']))\n",
    "    \n",
    "    metrics['mean_percent_change_before'] = np.mean(df_before['percent_change'])\n",
    "    metrics['wilcoxon_percent_change_before'] = (wilcoxon(df_before['percent_change']))\n",
    "    \n",
    "    metrics['mean_percent_change_after'] = np.mean(df_after['percent_change'])\n",
    "    metrics['wilcoxon_percent_change_after'] = (wilcoxon(df_after['percent_change']))\n",
    "    \n",
    "    metrics['percent_change_conf_int_before'] = t.interval(alpha=0.95, df=len(df_before['percent_change'])-1, loc=np.mean(df_before['percent_change']), scale=sem(df_before['percent_change']))\n",
    "    metrics['percent_change_conf_int_after'] = t.interval(alpha=0.95, df=len(df_after['percent_change'])-1, loc=np.mean(df_after['percent_change']), scale=sem(df_after['percent_change']))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get metrics for each region and outcome\n",
    "region_metrics ={}\n",
    "for region in forecast_dict.keys():\n",
    "    measures_metrics = {}\n",
    "    for measure in forecast_dict[region].keys():\n",
    "        itl_metrics = get_metrics(location = region,        \n",
    "                                     outcome = measure,\n",
    "                                     forecast = forecast_dict[region][measure],\n",
    "                                     prediction_start_date = prediction_start_date,\n",
    "                                     prediction_end_date = prediction_end_date)\n",
    "        \n",
    "        measures_metrics[measure] = itl_metrics\n",
    "    region_metrics[region] = measures_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_metrics['North Central']['Antenatal 4th Visit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percent_change(data, prediction_start_date):\n",
    "    \n",
    "    '''\n",
    "    Function to plot the percentage change of the outcomes and the predicted values\n",
    "    \n",
    "    @params:\n",
    "    data: Dataframe with the metrics from the forecast (pd.DataFrame)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df= data[data['month']==prediction_start_date].copy()\n",
    "    df = df.sort_values(['outcome', 'mean_percent_change_after'], ascending = False)\n",
    "    \n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(10,9)})\n",
    "    mpl.rcParams['font.size'] = 12.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "    spot =0\n",
    "    for outcome in set(df['outcome']): \n",
    "        spot +=1\n",
    "        plt.subplot(3,1,spot)\n",
    "\n",
    "        x  = df['location'][df['outcome']==outcome]\n",
    "        y = np.array(list(df['mean_percent_change_after'][df['outcome']==outcome]))\n",
    "        conf = np.array(list(df['percent_change_conf_int_after'][df['outcome']==outcome]))\n",
    "        yconf = np.c_[y-conf[:,0],conf[:,1]-y ].T\n",
    "\n",
    "        plt.plot(y,x,'.', color ='blue')\n",
    "        plt.axvline(x = 0, linewidth = 1, linestyle =\"--\", color ='grey')\n",
    "        title = '{}'.format(outcome_label_original[outcome])\n",
    "        plt.title(title, loc='center', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('percent change in {} counts'.format(y_axis_label[outcome]), fontsize =12, fontweight='bold')\n",
    "        plt.errorbar(y, x, xerr=yconf, fmt =' ', color ='blue')\n",
    "    suptitle = 'Mean and 95% CI of Percent Change in Predicted vs Actual Counts ({} {} to December 2020)'.format(prediction_start_date.strftime(\"%B\"),prediction_start_date.year)\n",
    "    plt.suptitle(suptitle,fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout(pad=4.0)\n",
    "    plt.savefig(\"plots/{}.png\".format(suptitle), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(data, prediction_start_date):\n",
    "    '''\n",
    "    Function to plot the difference of the outcomes and the predicted values\n",
    "    \n",
    "    @params:\n",
    "    data: Dataframe with the metrics from the forecast (pd.DataFrame)\n",
    "    prediction_start_date: Prediction start date (datetime)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df= data[data['month']==prediction_start_date].copy()\n",
    "    df = df.sort_values(['outcome', 'mean_change_after'], ascending = False)\n",
    "    \n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(11,9)})\n",
    "    mpl.rcParams['font.size'] = 12.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "    spot =0\n",
    "    for outcome in set(df['outcome']): \n",
    "        spot +=1\n",
    "        plt.subplot(3,1,spot)\n",
    "\n",
    "        x  = df['location'][df['outcome']==outcome]\n",
    "        y = np.array(list(df['mean_change_after'][df['outcome']==outcome]))\n",
    "        conf = np.array(list(df['change_conf_int_after'][df['outcome']==outcome]))\n",
    "        yconf = np.c_[y-conf[:,0],conf[:,1]-y ].T\n",
    "\n",
    "        plt.plot(y,x,'.', color ='blue')\n",
    "        plt.axvline(x = 0, linewidth = 1, linestyle =\"--\", color ='grey')\n",
    "        title = '{}'.format(outcome_label_original[outcome])\n",
    "        plt.title(title, loc='center', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('mean of the difference in predicted vs actual {} counts'.format(y_axis_label[outcome]), fontsize =12, fontweight='bold')\n",
    "        plt.errorbar(y, x, xerr=yconf, fmt =' ', color ='blue')\n",
    "    suptitle = 'Mean and 95% CI of Difference in Predicted vs Actual Counts ({} {} to December 2020)'.format(prediction_start_date.strftime(\"%B\"),prediction_start_date.year)\n",
    "    plt.suptitle(suptitle,fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout(pad=4.0)\n",
    "    plt.savefig(\"plots/{}.png\".format(suptitle), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame(columns = ['month','location', 'outcome', \n",
    "                                      'mape_before', 'mape_after', \n",
    "                                      'actual_mean_before', 'predicted_mean_before', \n",
    "                                      'actual_mean_after', 'predicted_mean_after', \n",
    "                                      'actual_median_before', 'predicted_median_before', \n",
    "                                      'actual_median_after', 'predicted_median_after', \n",
    "                                      'mean_change_before', 'change_conf_int_before',  'wilcoxon_change_before',\n",
    "                                      'mean_change_after',  'change_conf_int_after', 'wilcoxon_change_after',\n",
    "                                      'mean_percent_change_before','percent_change_conf_int_before',  'wilcoxon_percent_change_before',\n",
    "                                      'mean_percent_change_after','percent_change_conf_int_after', 'wilcoxon_percent_change_after'\n",
    "       ])\n",
    "\n",
    "for region in region_metrics.keys():\n",
    "    for outcome in region_metrics[region].keys():\n",
    "        metrics = region_metrics[region][outcome]\n",
    "        metrics['month'] = prediction_start_date\n",
    "        all_metrics = all_metrics.append(metrics, ignore_index = True)\n",
    "\n",
    "all_metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_metrics = all_metrics[['month','outcome','location', \n",
    "                                'predicted_mean_after','actual_mean_after', \n",
    "                                'mean_change_after', 'change_conf_int_after', 'wilcoxon_change_after',\n",
    "                                'mean_percent_change_after','percent_change_conf_int_after', 'wilcoxon_percent_change_after']]\n",
    "\n",
    "selected_metrics = selected_metrics.sort_values(['month','outcome', 'location'], ascending = [True,False, True])\n",
    "selected_metrics['change_conf_int_after'] = [(round(i[0],2),round(i[1],2)) for i in selected_metrics['change_conf_int_after']]\n",
    "selected_metrics['percent_change_conf_int_after'] = [(round(i[0],2),round(i[1],2)) for i in selected_metrics['percent_change_conf_int_after']]\n",
    "selected_metrics['wilcoxon_change_after'] = [round(i[1],4) for i in selected_metrics['wilcoxon_change_after']]\n",
    "selected_metrics['wilcoxon_percent_change_after'] = [round(i[1],4) for i in selected_metrics['wilcoxon_percent_change_after']]\n",
    "selected_metrics.to_csv('selected_metrics.csv',index=False)\n",
    "selected_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_diff(selected_metrics, '2020-03-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_percent_change(selected_metrics, '2020-03-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step takes at least 2 hours to run, the tuned parameters were saved in a pickle file to be used for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_start='2019-02-01'\n",
    "cutoff_end='2019-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_hyperparameters(location, outcome, data, cutoff_start='2019-02-01', cutoff_end='2019-10-01'):\n",
    "    '''\n",
    "    Function to tune the prophet model hyperparameters for the dataset.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    forecast: Dataframe with date and the outcome value for the geographical unit and outcome. (pd.DataFrame)\n",
    "    cutoff_start: Start date (datetime)\n",
    "    cutoff_end: End date (datetime)\n",
    "    \n",
    "    '''\n",
    "\n",
    "#     df = data[data['displayName'] == outcome].copy() \n",
    "    df = data.copy()\n",
    "    \n",
    "    cutoff_start = datetime.strptime(cutoff_start, '%Y-%m-%d')\n",
    "    cutoff_end = datetime.strptime(cutoff_end, '%Y-%m-%d')\n",
    "    cutoffs = pd.date_range(start=cutoff_start, end=cutoff_end, freq='MS')    \n",
    "    \n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.01, 0.05, 0.1],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    }\n",
    "    \n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        m = Prophet(interval_width=.95, \n",
    "                    growth ='linear',\n",
    "                    yearly_seasonality=False, \n",
    "                    weekly_seasonality = False, \n",
    "                    daily_seasonality = False,\n",
    "                    **params\n",
    "                   ).add_seasonality(\n",
    "                        name='yearly',\n",
    "                        period = 365,\n",
    "                        fourier_order = 5\n",
    "                   )\n",
    "        m.fit(df)  \n",
    "        df_cv = cross_validation(model=m, horizon='90 days', cutoffs=cutoffs, parallel=\"processes\")\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "    # Find the best parameters\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['rmse'] = rmses\n",
    "    tuning_results = tuning_results.sort_values('rmse')\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    \n",
    "    return tuning_results, best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tune the hyperparameters for all regions and outcomes\n",
    "region_hyperparameters ={}\n",
    "for region in regions:\n",
    "    measures_parameters = {}\n",
    "    for measure in final_columns:\n",
    "        data = df_copy.loc[df_copy['Region'] == region].copy()[[measure,'Date','Region']]\n",
    "        data = data[['Date', measure]]\n",
    "        data.columns = ['ds','y']\n",
    "        print(region,measure)\n",
    "        \n",
    "        tuning_results, best_params = tune_hyperparameters(location = region,\n",
    "                                                           outcome = measure,\n",
    "                                                           data = data, \n",
    "                                                           cutoff_start = cutoff_start, \n",
    "                                                           cutoff_end = cutoff_end)\n",
    "        \n",
    "        measures_parameters[measure] = tuning_results, best_params\n",
    "    region_hyperparameters[region] = measures_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the tuned hyperparameters to save computation time\n",
    "with open('tuned_params_nigeria_regions.pkl', 'wb') as handle:\n",
    "    pickle.dump(region_hyperparameters, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the previously saved tuned parameters\n",
    "with open('tuned_params/tuned_params_nigeria_regions.pkl', 'rb') as f:\n",
    "    region_hyperparameters = pickle.load(f)\n",
    "region_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview the tuned parameters\n",
    "for x in region_hyperparameters.keys():\n",
    "    for y in region_hyperparameters[x].keys():\n",
    "        z, best_params = region_hyperparameters[x][y]\n",
    "        print(x, y, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Get forecasts using tuned hyperparameters & Performance Evaluation using Model Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Functions for performance evaluation using Model Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(location, outcome, data, seasonality_mode='additive', changepoint_prior_scale=0.05, seasonality_prior_scale=10.0, cutoff_start='2019-02-01', cutoff_end='2019-10-01'):\n",
    "    \n",
    "    '''\n",
    "    Function for cross validation to evaluate the model's perfomance.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    data: Dataframe with date and the outcome value for the geographical unit and outcome. (pd.DataFrame)\n",
    "    seasonality_mode: tuned prophet model parameter (string)\n",
    "    changepoint_prior_scale: tuned prophet model parameter (double)\n",
    "    seasonality_prior_scale: tuned prophet model parameter (double)\n",
    "    cutoff_start: Prediction start date (datetime)\n",
    "    cutoff_end: Prediction end date (datetime)\n",
    "    \n",
    "    '''\n",
    "    df = data.copy()  \n",
    "\n",
    "    m = Prophet(interval_width=.95, \n",
    "            growth ='linear',\n",
    "            yearly_seasonality=False, \n",
    "            weekly_seasonality = False, \n",
    "            daily_seasonality = False,\n",
    "            seasonality_mode = seasonality_mode,\n",
    "            changepoint_prior_scale = changepoint_prior_scale,\n",
    "            seasonality_prior_scale = seasonality_prior_scale,\n",
    "            ).add_seasonality(\n",
    "                name='yearly',\n",
    "                period = 365,\n",
    "                fourier_order = 5\n",
    "            )\n",
    "    \n",
    "    m.fit(df)\n",
    "    \n",
    "    cutoff_start = datetime.strptime(cutoff_start, '%Y-%m-%d')\n",
    "    cutoff_end = datetime.strptime(cutoff_end, '%Y-%m-%d')\n",
    "    cutoffs = pd.date_range(start=cutoff_start, end=cutoff_end, freq='MS')\n",
    "    \n",
    "    df_cv = cross_validation(model=m, horizon='90 days', cutoffs=cutoffs)\n",
    "    \n",
    "    return df_cv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_metric(location, outcome, df_cv, prediction_start_date):\n",
    "    \n",
    "    '''\n",
    "    Function to plot the cross-validation metrics.\n",
    "    \n",
    "    @params:\n",
    "    location: Geographical unit (string)\n",
    "    outcome: Outcome measure (string)\n",
    "    df_cv: Dataframe with date and the outcome value for the geographical unit and outcome. (pd.DataFrame)\n",
    "    seasonality_mode: tuned prophet model parameter (string)\n",
    "    changepoint_prior_scale: tuned prophet model parameter (double)\n",
    "    seasonality_prior_scale: tuned prophet model parameter (double)\n",
    "    cutoff_start: Prediction start date (datetime)\n",
    "    \n",
    "    '''\n",
    "    sns.set(rc={'figure.figsize':(10,8)})\n",
    "    sns.set_style(\"white\")\n",
    "    mpl.rcParams['font.size'] = 8.0\n",
    "    mpl.rcParams[\"font.weight\"] = \"bold\"\n",
    "    mpl.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    \n",
    "    plot_cross_validation_metric(df_cv, metric='mape')\n",
    "    plt.xticks(fontsize =18, fontweight='bold')\n",
    "    plt.yticks(fontsize =18, fontweight='bold') \n",
    "    plt.xlabel('Horizon',fontsize =18, fontweight='bold')\n",
    "    plt.ylabel('MAPE', fontsize =18, fontweight='bold')\n",
    "        \n",
    "    prediction_start_date = datetime.strptime(prediction_start_date, '%Y-%m-%d')\n",
    "    title = 'MAPE for {} in {} ({} {})'.format(outcome_label_original[outcome], location, prediction_start_date.strftime(\"%B\"),prediction_start_date.year)\n",
    "    \n",
    "    plt.title(title,fontsize = 20, fontweight='bold')\n",
    "    plt.savefig(\"plots/{}.png\".format(title),  dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Run the ITS & Cross-validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_dict_tuned = {}\n",
    "\n",
    "for region in regions:\n",
    "    measures_forecast_tuned = {}\n",
    "    forecast_dict_tuned[region] = {}\n",
    "    for measure in final_columns:\n",
    "        forecast_dict_tuned[region][measure] = {}\n",
    "        data = df_copy.loc[df_copy['Region'] == region].copy()[[measure,'Date','Region']]\n",
    "        data = data[['Date', measure]]\n",
    "        data.columns = ['ds','y']\n",
    "        \n",
    "        x, best_params = region_hyperparameters[region][measure]\n",
    "\n",
    "        # Get forecast\n",
    "        forecast = get_forecasts(location = region,\n",
    "                                          outcome = measure,\n",
    "                                          data = data, \n",
    "                                          seasonality_mode = best_params['seasonality_mode'],\n",
    "                                          changepoint_prior_scale = best_params['changepoint_prior_scale'],\n",
    "                                          seasonality_prior_scale = best_params['seasonality_prior_scale'],\n",
    "                                          prediction_start_date = prediction_start_date,\n",
    "                                          prediction_end_date = prediction_end_date)\n",
    "\n",
    "        forecast_dict_tuned[region][measure]['forecast'] = forecast\n",
    "\n",
    "\n",
    "        # Get Metrics\n",
    "        itl_metrics_tuned = get_metrics(location = region,        \n",
    "                     outcome = measure,\n",
    "                     forecast = forecast,\n",
    "                     prediction_start_date = prediction_start_date,\n",
    "                     prediction_end_date = prediction_end_date)\n",
    "\n",
    "        forecast_dict_tuned[region][measure]['metrics'] = itl_metrics_tuned\n",
    "\n",
    "        #cross validation\n",
    "        df_cv = cross_validate(location = region,\n",
    "                               outcome = measure,\n",
    "                               data = data, \n",
    "                               seasonality_mode = best_params['seasonality_mode'],\n",
    "                               changepoint_prior_scale = best_params['changepoint_prior_scale'],\n",
    "                               seasonality_prior_scale = best_params['seasonality_prior_scale'],\n",
    "                               cutoff_start = cutoff_start, \n",
    "                               cutoff_end = cutoff_end)\n",
    "\n",
    "        forecast_dict_tuned[region][measure]['df_cv'] = df_cv\n",
    "\n",
    "\n",
    "        df_p = performance_metrics(df_cv)\n",
    "\n",
    "        forecast_dict_tuned[region][measure]['df_p'] = df_p\n",
    "\n",
    "\n",
    "        # plots\n",
    "        plot_its(location = region,        \n",
    "                             outcome = measure,\n",
    "                             forecast = forecast,\n",
    "                             prediction_start_date = prediction_start_date,\n",
    "                             prediction_end_date = prediction_end_date)\n",
    "\n",
    "        plot_cumulative(location = region,        \n",
    "                             outcome = measure,\n",
    "                             forecast = forecast,\n",
    "                             prediction_start_date = prediction_start_date,\n",
    "                             prediction_end_date = prediction_end_date)\n",
    "\n",
    "        plot_cv_metric(location = region,\n",
    "                                   outcome = measure,\n",
    "                                   df_cv = df_cv,\n",
    "                                   prediction_start_date = prediction_start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in region_hyperparameters.keys():\n",
    "    for y in region_hyperparameters[x].keys():\n",
    "        z, best_params = region_hyperparameters[x][y]\n",
    "        print(x, y, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output to save computation time\n",
    "with open('forecast_dict_tuned_nigeria_regions.pkl', 'wb') as handle:\n",
    "    pickle.dump(forecast_dict_tuned, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_metrics(region_metrics:dict(), prediction_start_date = prediction_start_date):\n",
    "    all_metrics = pd.DataFrame(columns = ['month','location', 'outcome', \n",
    "                                      'mape_before', 'mape_after', \n",
    "                                      'actual_mean_before', 'predicted_mean_before', \n",
    "                                      'actual_mean_after', 'predicted_mean_after', \n",
    "                                      'actual_median_before', 'predicted_median_before', \n",
    "                                      'actual_median_after', 'predicted_median_after', \n",
    "                                      'mean_change_before', 'change_conf_int_before',  'wilcoxon_change_before',\n",
    "                                      'mean_change_after',  'change_conf_int_after', 'wilcoxon_change_after',\n",
    "                                      'mean_percent_change_before','percent_change_conf_int_before',  'wilcoxon_percent_change_before',\n",
    "                                      'mean_percent_change_after','percent_change_conf_int_after', 'wilcoxon_percent_change_after'\n",
    "       ])\n",
    "\n",
    "    for region in region_metrics.keys():\n",
    "        for outcome in region_metrics[region].keys():\n",
    "            metrics = region_metrics[region][outcome]['metrics']\n",
    "            metrics['month'] = prediction_start_date\n",
    "            all_metrics = all_metrics.append(metrics, ignore_index = True)\n",
    "            \n",
    "\n",
    "\n",
    "    selected_metrics = all_metrics[['month','outcome','location', \n",
    "                                'predicted_mean_after','actual_mean_after', \n",
    "                                'mean_change_after', 'change_conf_int_after', 'wilcoxon_change_after',\n",
    "                                'mean_percent_change_after','percent_change_conf_int_after', 'wilcoxon_percent_change_after']]\n",
    "\n",
    "    selected_metrics = selected_metrics.sort_values(['month','outcome', 'location'], ascending = [True,False, True])\n",
    "    selected_metrics['change_conf_int_after'] = [(round(i[0],2),round(i[1],2)) for i in selected_metrics['change_conf_int_after']]\n",
    "    selected_metrics['percent_change_conf_int_after'] = [(round(i[0],2),round(i[1],2)) for i in selected_metrics['percent_change_conf_int_after']]\n",
    "    selected_metrics['wilcoxon_change_after'] = [round(i[1],4) for i in selected_metrics['wilcoxon_change_after']]\n",
    "    selected_metrics['wilcoxon_percent_change_after'] = [round(i[1],4) for i in selected_metrics['wilcoxon_percent_change_after']]\n",
    "    selected_metrics.to_csv('selected_metrics.csv',index=False)\n",
    "    \n",
    "    return selected_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create important metrics\n",
    "selected_important_metrics = create_df_metrics(forecast_dict_tuned,prediction_start_date)\n",
    "\n",
    "# plot the important metrics\n",
    "plot_diff(selected_important_metrics, prediction_start_date)\n",
    "plot_percent_change(selected_important_metrics, prediction_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
